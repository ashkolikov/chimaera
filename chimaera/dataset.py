import gc
import functools

import numpy as np
from tensorflow.keras.utils import Sequence
from .utils import *

from cooler import Cooler
import cooltools.snipping
from cooltools.lib.numutils import zoom_array
from scipy.ndimage import zoom
from functools import partial

from multiprocessing import Pool

from .plot import *

class DataMaster(object):
    """Loads data for training
    
     hic_file: path to file with Hi-ะก maps;
     genome_path: path to genome fasta file or to folder
with chromosomes' files;
     dna_fragment_length: length of a DNA fragment associated with each sample (X);
     hic_fragment_length: size of Hi-C snippet associated with each sample (y);
     sigma: sigma in gaussian filter for maps;
     chroms_to_exclude: chomosomes not used in training;
     chroms_to_include: chomosomes used in training - if both args are not None chroms_to_include is a priority;
     viewframe_path: path to file with tsv chrom-start-end genomic regions;
     blacklist_path: path to file with tsv chrom-start-end of blacklist regions. Any region overlapping blacklisted will be removed.
     nthreads_snipper: number of threads for snipping
     scale: None (no scaling) or tuple of ints, scaling values in Hi-C maps. Note that it affects the decoder last layer activation function.
     normalize: scale using global min&max ('gloabal') or each scal map separately ('each');
     min_max: min and max for scaling, is used when adding smth to the dataset, technical arguement;
     zoomify_map_to: map size in pixels, the one that will be subjected to autoencoder, leave None if preserving original size;
     nan_threshold: highest permissible percentage of missing values in a map;
     rev_comp: stochastic reverse complement while training;
     stochastic_sampling: sample with random shifts along the genome while training (works not good in most cases);
     shift_repeats: sample with fixed shifts along the genome while training (e.g. if shift_repeats is 4, each position in the genome will be
        presented in the sample for times in fragments with a shift of 1/4 of their length). Note that this argument increases the size of the dataset;
     expand_dna: use DNA context for prediction (a half of a fragment length
        at both sides). Note that this argument increases the size of the dataset twice;
     dna_encoding: 'one-hot' or 'embedding';
     val_split: scheme of validation sample generation. Is a tuple of a word:
        'first' - first n in sample
        'last' - last n in sample
        'random'
        chromosome name + position of center (e.g. 'chr5 24510000'), and a number - integer (number of objects in sample) or a proportion;
     sample_seed: seed for random subsample of the validation sample used for graphic monitoring, doesn't affect anyting important.


    Class attributes:
    Private:
        _cooler
        _bin_table - table of genomic bines used for samples creatin. Each bin is a window center for the region.
        _viewframe - genomic regions (chromosomes or chromosomal arms)
        _DNA
        _min_max
        _names
        _snipper - snipper that loads the snips
        _mapped_len - size of DNA for one sample
        _dna_len - real size of DNA for one sample
        _binsize - resolution of Hi-C maps provided with cooler
        _zoom_rate - zoom rate for making Hi-C maps fitting the required window size
        _idx_x_train, _idx_x_val, _idx_y_train,_idx_y_val - indexes of samples in the bin table
        _hic_window_table - table of genomic windows for Hi-C in samples, chrom-start-end format, generated by snipping.make_bin_aligned_windows with hic_fragment_length
        _dna_window_table - table of genomic windows for DNA in samples, chrom-start-end format, generated by snipping.make_bin_aligned_windows with dna_fragment_length

    Public:
        run_params - list of parameters used for the run
        x_val_sample, y_val_sample, x_train_sample, y_train_sample - subsamples of real data for visualization
        x_train, x_val - DNA of the samples encoded by DNALoader
        y_train, y_val - Hi-C snippets of the samples encoded by HiCLoader

    """
    def __init__(self,
                 cool_path,
                 genome_path,
                 dna_fragment_length,
                 hic_fragment_length,
                 viewframe = None,
                 blacklist = None,
                 chroms_to_exclude = [],
                 chroms_to_include = [],
                 nthreads_snipper=1,
                 sigma=None,
                 scale = (0, 1),
                 norm_regime = 'global',
                 min_max = (None, None),
                 final_snip_size = 64,
                 nan_threshold = 0.2,
                 rev_comp = False,
                 stochastic_sampling = False,
                 shift_repeats = 1,
                 expand_dna = True,
                 dna_encoding = 'one-hot',
                 split_method = ('first', 500),
                 sample_seed = 0):

        if stochastic_sampling and (shift_repeats > 1):
            raise ValueError("Stochastic sampling and shift_repeats can't be used together")
        if (split_method[0] == 'random') and (stochastic_sampling or (shift_repeats > 1)):
            raise ValueError("Random split is incorrect in not fixed dataset")

        # TODO: replace it with a single parameters dictionary:
        self.run_params = {
            "cool_path": cool_path,
            "genome_path": genome_path,
            "viewframe": viewframe,
            "blacklist": blacklist,
            "dna_fragment_length": dna_fragment_length,
            "hic_fragment_length": hic_fragment_length,
            "final_snip_size": final_snip_size,
            "nan_threshold": nan_threshold,
            "stochastic_sampling": stochastic_sampling,
            "shift_repeats": shift_repeats,
            "expand_dna": expand_dna,
            "split_method": split_method,
            "rev_comp": rev_comp,
            "dna_encoding": dna_encoding,
            "sample_seed": sample_seed,
            "chroms_to_exclude": chroms_to_exclude, # TODO: re-implement
            "chroms_to_include": chroms_to_include,
            "min_max": min_max,
            "scale": scale,
            "norm_regime": norm_regime,
            "sigma": sigma,
        }

        # Pre-load cooler (no dump of snippets into RAM here):
        self._cooler = Cooler(cool_path)
        self._binsize = self._cooler.binsize

        # Make bin table and remove blacklisted regions
        bin_table = self._cooler.bins()[:]
        if blacklist is not None:
            if isinstance(blacklist, str):
                blacklist = bioframe.read_table(blacklist_path, schema="bed4", index_col=False)
            try:
                bin_table = bioframe.subtract(bin_table, blacklist)
            except ValueError as e:
                raise ValueError(
                    "Blacklist table is incorrect, please, comply with the format. "
                ) from e

        # Read the viewframe (regions table):
        if viewframe is None:
            view_df = bioframe.make_viewframe([(chrom, 0, l, chrom) for chrom, l in self._cooler.chromsizes.items()])
        elif isinstance(viewframe, str):
            view_df = bioframe.read_table(viewframe, schema="bed4", index_col=False)
            try:
                view_df = bioframe.make_viewframe(view_df, check_bounds=self._cooler.chromsizes)
            except ValueError as e:
                raise ValueError(
                    "View table is incorrect, please, comply with the format. "
                ) from e
        else:
            try:
                view_df = bioframe.make_viewframe(viewframe, check_bounds=self._cooler.chromsizes)
            except ValueError as e:
                raise ValueError(
                    "View table is incorrect, please, comply with the format. "
                ) from e
        self._viewframe = view_df

        # Retain only bins provided in a viewframe:
        selection = bioframe.overlap(bin_table, self._viewframe, how='right', return_input=False).index
        bin_table = bin_table.loc[selection, :]
        self._bin_table = bin_table


        # Create genomic windows of hic_fragment_length size and annotate them by viewframe:
        hic_window_table = cooltools.snipping.make_bin_aligned_windows(
            self._cooler.binsize,
            self._bin_table['chrom'],
            self._bin_table['start'],
            flank_bp=hic_fragment_length//2)
        self._hic_window_table = bioframe.overlap(hic_window_table, view_df, how='inner').rename({'name_': 'region'}, axis=1).drop(['chrom_', 'start_', 'end_'], axis=1)


        # Read FASTA sequences into dictionary:
        self._dna, self._names = load_fasta(genome_path, self._cooler, [], []) # TODO: remove extra args
        # Create genomic windows of dna_fragment_length size and select only the ones accepted for Hi-C:
        dna_window_table = cooltools.snipping.make_bin_aligned_windows(
            self._cooler.binsize,
            self._bin_table['chrom'],
            self._bin_table['start'],
            flank_bp=dna_fragment_length//2)
        self._dna_window_table = dna_window_table.loc[self._hic_window_table.index, :]

        # Retain only selected bins in bin_table:
        self._bin_table = self._bin_table.loc[self._hic_window_table.index, :]


        initial_snip_size = hic_fragment_length // self._binsize
        if final_snip_size:
            zoom_rate = final_snip_size / initial_snip_size
            self._zoom_rate = zoom_rate
        else:
            self._zoom_rate = 1
        print(f'For each sample: select {initial_snip_size}x{initial_snip_size} snippets, zoomify to {final_snip_size}x{final_snip_size} (Ys) and align with {dna_fragment_length} nucleotides (Xs)')


        # Load Hi-C dataset:
        custom_transform = functools.partial(chimaera_transform,
                min_frac_valid_pixels=nan_threshold,
                remove_diag=2,
                fill_diag=0,
                fill_missing=0,
                sigma=sigma)
        self._snipper = TransformingSnipper(self._cooler,
                                       view_df=self._viewframe,
                                       transform=custom_transform,
                                       padding=2)
        with Pool(nthreads_snipper) as pool:
            stack = cooltools.snipping.pileup(
                self._hic_window_table,
                self._snipper.select,
                self._snipper.snip,
                map=pool.map)

        ys = stack.T
        # Resize:
        if final_snip_size is not None or final_snip_size != snippet.shape[0]:
            ys = np.array([zoom_array(snip, (final_snip_size, final_snip_size), same_sum=True) for snip in ys])

        # Remove non-readable regions:
        whitelist = np.isfinite(ys.sum(axis=1).sum(axis=1))
        ys = ys[whitelist]
        print(f"Only {sum(whitelist)} regions are readable out of {len(self._bin_table)} initial") # TODO: replace with logging.info for debug level control
        self._bin_table = self._bin_table.loc[whitelist, :]
        self._hic_window_table = self._hic_window_table.loc[whitelist, :]
        self._dna_window_table = self._dna_window_table.loc[whitelist, :]

        # Rescale ys:
        ys = rescale_ys(ys, scale=scale, norm_regime=norm_regime, min_max=min_max)
        self._hic = ys

        # Split train and test, generates indexes of the bin table that will be included into train/test,
        # Note that this procedure guarantees that no overlapping genomic windows are in train and test simultaneously:
        # TODO: introduce random_state?
        self._idx_x_train, self._idx_x_val, self._idx_y_train, self._idx_y_val = split_data(self._bin_table,
                                                                            method=split_method[0],
                                                                            params={'val_split': split_method[1]})
        self._idx_x_train_sample, self._idx_x_val_sample, self._idx_y_train_sample, self._idx_y_val_sample = \
            cast_samples(self._idx_x_train, self._idx_x_val, self._idx_y_train, self._idx_y_val, nsamples=9, seed=None)

        print(f"Full dataset: {len(self._bin_table)}, train size: {len(self._idx_x_train)}, validation size: {len(self._idx_x_val)} samples")

        # Load train and test:
        self.x_train = DNALoader(self._idx_x_train, self._dna_window_table, self._dna)
        self.x_val   = DNALoader(self._idx_x_val,   self._dna_window_table, self._dna)
        self.y_train = HiCLoader(self._idx_y_train, self._hic)
        self.y_val   = HiCLoader(self._idx_y_val,   self._hic)

        self.x_train_sample = DNALoader(self._idx_x_train_sample, self._dna_window_table, self._dna)
        self.x_val_sample   = DNALoader(self._idx_x_val_sample,   self._dna_window_table, self._dna)
        self.y_train_sample = HiCLoader(self._idx_y_train_sample, self._hic)
        self.y_val_sample   = HiCLoader(self._idx_y_val_sample,   self._hic)


class DNALoader():
    """Saves memory and helps to make array of one-hot-encoded DNA batch
    only when it is needed. Input data of model is stored in DNA string 
    and array of indices"""

    def __init__(self, idx_xs, dna_table, dna, force_lower=True, alphabet={'a' : 0, 'c' : 1, 'g' : 2, 't' : 3, 'n' : 4}):
        self.input_data = idx_xs
        self.dna_table = dna_table
        self.dna = dna
        self.len = len(self.input_data)
        self.forced_lower = force_lower
        self.alphabet = alphabet

    def __getitem__(self, i):
        if isinstance(i, tuple): # TODO: remove?
            if len(i) == 2 and isinstance(i[1], int):
                i, shift = i
        else:
            shift = 0
        if isinstance(i, slice):
            start = i.start if i.start else 0
            start = start if start >= 0 else self.len - start
            stop = i.stop if i.stop else self.len    
            stop = stop if stop >= 0 else self.len - stop    
            stop = min(stop, len(self))
            iterator = range(start, stop)
        elif isinstance(i, int):
            iterator = [i]
        else:
            iterator = i

        batch = []
        for query in iterator:
            chrom, start, end = self.dna_table.loc[self.idx_xs[query], ['chrom', 'start', 'end']]
            start += shift
            end += shift
            seq = self.dna[chrom][start : end]
            if self.forced_lower:
                seq = seq.lower()
            seq_encoded = one_hot(seq, self.alphabet)
            batch.append(seq_encoded)
        return np.array(batch)

    def __len__(self):
        return self.len


class HiCLoader():
    def __init__(self, idx_ys, hic):
        self.idx_ys = idx_ys
        self.len = len(self.idx_ys)
        self.ys = hic

    def show(self, i):
        plot_map(self[i])

    def __getitem__(self, i):
        # if isinstance(i, tuple): # TODO: remove?
        #     if len(i) == 2 and isinstance(i[1], int):
        #         i, shift = i
        # else:
        #     shift = 0
        if isinstance(i, slice):
            start = i.start if i.start else 0
            start = start if start >= 0 else self.len - start
            stop = i.stop if i.stop else self.len    
            stop = stop if stop >= 0 else self.len - stop    
            stop = min(stop, len(self))
            ind = list(range(start, stop))
        elif isinstance(i, int):
            ind = [i]
        else:
            ind = i
        batch = self.ys[ind]
        return np.array(batch)

    def __len__(self):
        return self.len


class DataGenerator(Sequence):
    '''For loading into model'''
    def __init__(self, data, train, batch_size = 4, shuffle = True, encoder = None):
        if train:
            self.X = data.x_train
            if data.stochastic_sampling:
                self.y = data.y_train
            else:
                self.y = data.y_latent_train
        else:
            self.X = data.x_val
            if data.stochastic_sampling or data.split_method == 'test':
                self.y = data.y_val                
            else:
                self.y = data.y_latent_val

        if data.stochastic_sampling and not encoder:
            raise ValueError('For training on dataset using stochastic sampling pass your encoder model to the encoder arguement')
        self.data = data
        self.batch_size = batch_size
        self.train = train
        self.shuffle = shuffle
        self.encoder = encoder
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.X) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]
        if not self.data.stochastic_sampling:
            X = self.X[indexes]
            y = self.y[indexes]
        else:
            if self.train:
                shift = np.random.choice(self.data.mapped_len)
                y_shift = int(shift / self.data.mapped_len * self.data.map_size)
                X = self.X[indexes, shift]
                y = self.y[indexes, y_shift]
                if self.data.rev_comp:
                    X, y = self.stochastic_rev_comp(X, y)
                y = self.encoder.predict(y)
            else:
                X = self.X[indexes]
                y = self.y[indexes]
                y = self.encoder.predict(y)
        return X, y
    
    def on_epoch_end(self):
        self.indexes = np.arange(len(self.X))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def stochastic_rev_comp(self, X, y):
        ind = np.random.random(len(X)) > 0.5
        if self.data.dna_encoding == 'one_hot':
            X[ind] = np.flip(X[ind], axis=(1, 2))
        else:
            X[ind] = 3 - X[ind]
            X[X==-1] = 4
        return X, y


class HiCDataGenerator(Sequence):
    '''For loading into model'''
    def __init__(self, data, rotate = True, shuffle = True):
        self.X = data.y_train
        self.batch_size = 64
        self.rotate = rotate
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.X) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]
        X = self.X[indexes]
        if self.rotate:
            X = self.stochastic_rotate(X)
        return X, X

    def on_epoch_end(self):
        self.indexes = np.arange(len(self.X))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def stochastic_rotate(self, a):
        ind = np.random.random(len(a)) > 0.5
        a[ind] = np.flip(a[ind], axis=(1, 2))
        return a
